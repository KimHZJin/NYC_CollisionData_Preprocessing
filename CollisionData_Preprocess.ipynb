{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfKndnZ_YmY4"
      },
      "source": [
        "\n",
        "**Final Project**\n",
        "\n",
        "Kim Jin (hj1314@nyu.edu)\n",
        "\n",
        "11/26/2024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PVC0RNPYB4-",
        "outputId": "cbd5bd8a-8bea-433c-ec8c-3b5e3ab8e2b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import stat\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import re\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7JzD1rafSgF"
      },
      "source": [
        "#Notes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMGdAf6-XzGN"
      },
      "outputs": [],
      "source": [
        "https://www.nyc.gov/site/nypd/stats/traffic-data/traffic-data-collision.page"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Ehj0aNUYWYY"
      },
      "outputs": [],
      "source": [
        "## Load the files\n",
        "## skip some rows to exclude the notes.\n",
        "staten_island = pd.read_excel('sihacc.xlsx', sheet_name=None, skiprows=4)\n",
        "queens = pd.read_excel('qnhacc.xlsx', sheet_name=None, skiprows=4)\n",
        "brooklyn = pd.read_excel('bkhacc.xlsx', sheet_name=None, skiprows=4)\n",
        "bronx = pd.read_excel('bxhacc.xlsx', sheet_name=None, skiprows=4)\n",
        "manhattan = pd.read_excel('mnhacc.xlsx', sheet_name=None, skiprows=4)\n",
        "staten_island_i = pd.read_excel('siacc.xlsx', sheet_name=None, skiprows=3)\n",
        "queens_i = pd.read_excel('qnacc.xlsx', sheet_name=None, skiprows=3)\n",
        "brooklyn_i = pd.read_excel('bkacc.xlsx', sheet_name=None, skiprows=3)\n",
        "bronx_i = pd.read_excel('bxacc.xlsx', sheet_name=None, skiprows=3)\n",
        "manhattan_i = pd.read_excel('mnacc.xlsx', sheet_name=None, skiprows=3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJDCHsoteHMk"
      },
      "source": [
        "#Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zE5YcViGNzLK"
      },
      "outputs": [],
      "source": [
        "## also drop the last 6 rows for they are notes\n",
        "all_dictionaries = {\n",
        "    \"staten_island\": staten_island,\n",
        "    \"queens\": queens,\n",
        "    \"brooklyn\": brooklyn,\n",
        "    \"bronx\": bronx,\n",
        "    \"manhattan\": manhattan,\n",
        "    \"staten_island_i\": staten_island_i,\n",
        "    \"queens_i\": queens_i,\n",
        "    \"brooklyn_i\": brooklyn_i,\n",
        "    \"bronx_i\": bronx_i,\n",
        "    \"manhattan_i\": manhattan_i,\n",
        "}\n",
        "\n",
        "# Function to drop the last 6 rows for each sheet in a dictionary\n",
        "def drop_last_rows(data_dict, n=6):\n",
        "    for sheet_name, df in data_dict.items():\n",
        "        data_dict[sheet_name] = df.iloc[:-n]  # Retain all rows except the last `n`\n",
        "\n",
        "# Apply the function to all dictionaries\n",
        "for data_dict in all_dictionaries.values():\n",
        "    drop_last_rows(data_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DroPOd18EXiL"
      },
      "outputs": [],
      "source": [
        "## fix typo in contributing-factor sheet:ColllisionKey\n",
        "\n",
        "all_dictionaries = {\n",
        "    \"staten_island\": staten_island,\n",
        "    \"queens\": queens,\n",
        "    \"brooklyn\": brooklyn,\n",
        "    \"bronx\": bronx,\n",
        "    \"manhattan\": manhattan,\n",
        "    \"staten_island_i\": staten_island_i,\n",
        "    \"queens_i\": queens_i,\n",
        "    \"brooklyn_i\": brooklyn_i,\n",
        "    \"bronx_i\": bronx_i,\n",
        "    \"manhattan_i\": manhattan_i,\n",
        "}\n",
        "\n",
        "def rename_colllisionkey_to_collisionkey(data_dict):\n",
        "    for sheet_name, df in data_dict.items():\n",
        "        df.rename(columns={\"ColllisionKey\": \"CollisionKey\"}, inplace=True)\n",
        "\n",
        "for data_dict in all_dictionaries.values():\n",
        "    rename_colllisionkey_to_collisionkey(data_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBPbJSLtEaNy"
      },
      "outputs": [],
      "source": [
        "## Convert dtype of 'CollisionID', 'ColllisionKey' to str\n",
        "def convert_columns_to_string(data_dict, columns):\n",
        "    for sheet_name, df in data_dict.items():\n",
        "        for column in columns:\n",
        "            if column in df.columns:\n",
        "                df[column] = df[column].astype(str)  # Convert to string\n",
        "    return data_dict\n",
        "\n",
        "all_dictionaries = [\n",
        "    staten_island, queens, brooklyn, bronx, manhattan,\n",
        "    staten_island_i, queens_i, brooklyn_i, bronx_i, manhattan_i\n",
        "]\n",
        "\n",
        "columns_to_convert = ['CollisionID', 'ColllisionKey']\n",
        "\n",
        "all_dictionaries = [\n",
        "    convert_columns_to_string(data_dict, columns_to_convert) for data_dict in all_dictionaries\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a9jybPPEe1p"
      },
      "source": [
        "\n",
        "- merge in three ways: injured/death counts, factors, and all\n",
        "- add roadway type code and borough\n",
        "- drop OccurrencePrecinctCode, RoadwayReferenceMarker, RoadwayReferenceMarker, RoadwayLocationDescription"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYdtmWe8EiRI"
      },
      "outputs": [],
      "source": [
        "## add column: Borough\n",
        "\n",
        "all_dictionaries = {\n",
        "    \"staten_island\": staten_island,\n",
        "    \"queens\": queens,\n",
        "    \"brooklyn\": brooklyn,\n",
        "    \"bronx\": bronx,\n",
        "    \"manhattan\": manhattan,\n",
        "    \"staten_island_i\": staten_island_i,\n",
        "    \"queens_i\": queens_i,\n",
        "    \"brooklyn_i\": brooklyn_i,\n",
        "    \"bronx_i\": bronx_i,\n",
        "    \"manhattan_i\": manhattan_i,\n",
        "}\n",
        "\n",
        "def add_borough_column_after_collisionkey(data_dict, name):\n",
        "    borough_name = re.sub(r'_i$', '', name)\n",
        "    for sheet_name, df in data_dict.items():\n",
        "        collision_key_idx = df.columns.get_loc('CollisionKey') + 1\n",
        "        df.insert(collision_key_idx, 'Borough', borough_name)\n",
        "\n",
        "for dict_name, data_dict in all_dictionaries.items():\n",
        "    add_borough_column_after_collisionkey(data_dict, dict_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gh5IpozbErfQ"
      },
      "outputs": [],
      "source": [
        "## Now, RoadType\n",
        "## For intersection, just I\n",
        "## For RoadwayType, change into RoadType and so on\n",
        "def add_roadtype_column_after_borough(data_dict):\n",
        "    for sheet_name, df in data_dict.items():\n",
        "        borough_idx = df.columns.get_loc('Borough') + 1\n",
        "        df.insert(borough_idx, 'RoadType', \"I\")\n",
        "\n",
        "for dict_name, data_dict in all_dictionaries.items():\n",
        "    if dict_name.endswith(\"_i\"):\n",
        "        add_roadtype_column_after_borough(data_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRQZpm3tEs1M"
      },
      "outputs": [],
      "source": [
        "## A bit tricky part:\n",
        "## first change the column name from RoadwayTypeCode to RoadType for insistent\n",
        "def rename_roadwaytypecode_to_roadtype(data_dict):\n",
        "    data_dict['RoadwayCollisions'].rename(columns={'RoadwayTypeCode': 'RoadType'}, inplace=True)\n",
        "\n",
        "for dict_name, data_dict in all_dictionaries.items():\n",
        "    if not dict_name.endswith(\"_i\"):\n",
        "        rename_roadwaytypecode_to_roadtype(data_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbOJNU-JExhf"
      },
      "outputs": [],
      "source": [
        "## Add RoadType column to ContrFactor sheet\n",
        "def add_roadtype_to_factors(data_dict):\n",
        "    collisions_df = data_dict['RoadwayCollisions']\n",
        "    factors_df = data_dict['RoadwayVehiclesContrFactors']\n",
        "\n",
        "    roadtype_mapping = collisions_df[['CollisionID', 'RoadType']].drop_duplicates().set_index('CollisionID')['RoadType']\n",
        "\n",
        "    factors_df['RoadType'] = factors_df['CollisionID'].map(roadtype_mapping)\n",
        "\n",
        "    borough_idx = factors_df.columns.get_loc('Borough') + 1\n",
        "    columns = list(factors_df.columns)\n",
        "    columns.remove('RoadType')\n",
        "    columns.insert(borough_idx, 'RoadType')\n",
        "    data_dict['RoadwayVehiclesContrFactors'] = factors_df[columns]\n",
        "\n",
        "for dict_name, data_dict in all_dictionaries.items():\n",
        "    if not dict_name.endswith(\"_i\"):\n",
        "        add_roadtype_to_factors(data_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhLEGJjVEyp2"
      },
      "outputs": [],
      "source": [
        "## Now let's start merging\n",
        "## Again, I plan to merge and create 3 dfs\n",
        "## One for each sheet, then everything\n",
        "## But, multicollinearity and sparcity will be issues\n",
        "## since we have lots of one-hot encoding\n",
        "## Here I'll also drop some columns that I really don't think we need\n",
        "## Let's start with Collisions\n",
        "## I drops some address columns, and only keep Address, which is RoadwayName and IntersectionAddress\n",
        "## and for Intersection sheet I change collision_at_intersection to collision_at_address for consistency\n",
        "\n",
        "def drop_repeated_columns(data_dict):\n",
        "    collisions_df = data_dict['RoadwayCollisions']\n",
        "\n",
        "    collisions_df.rename(columns={'RoadwayName': 'Address'}, inplace=True)\n",
        "    data_dict['RoadwayCollisions'].drop(\n",
        "        columns=['RoadwayDirection', 'RoadwayLocationDescription', 'RoadwayReferenceMarker'],\n",
        "        inplace=True,\n",
        "        errors='ignore'\n",
        "    )\n",
        "\n",
        "    data_dict['RoadwayCollisions'] = collisions_df\n",
        "\n",
        "for dict_name, data_dict in all_dictionaries.items():\n",
        "    if not dict_name.endswith(\"_i\"):\n",
        "        drop_repeated_columns(data_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGD03MgxE1r2"
      },
      "outputs": [],
      "source": [
        "def update_columns_for_i(data_dict):\n",
        "    for sheet_name, df in data_dict.items():\n",
        "        df.drop(columns=['IntersectingStreet', 'CrossStreet'], inplace=True, errors='ignore')\n",
        "\n",
        "        df.rename(\n",
        "            columns={\n",
        "                'Collision_ at_Intersection': 'Collision_ at_Location',\n",
        "                'IntersectionAddress': 'Address'\n",
        "            },\n",
        "            inplace=True\n",
        "        )\n",
        "\n",
        "for dict_name, data_dict in all_dictionaries.items():\n",
        "    if dict_name.endswith(\"_i\"):\n",
        "        update_columns_for_i(data_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBHSDeXeE3vo",
        "outputId": "726316bf-a0bb-45f0-99db-7815ebea1077"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Do IntersectCollisions (_i) and RoadwayCollisions (non-_i) have the same columns? True\n"
          ]
        }
      ],
      "source": [
        "# Function to check column name consistency between IntersectCollisions and RoadwayCollisions\n",
        "def check_column_consistency(dictionaries):\n",
        "    i_columns = set()\n",
        "    for dict_name, data_dict in dictionaries.items():\n",
        "        if dict_name.endswith(\"_i\") and 'IntersectCollisions' in data_dict:\n",
        "            i_columns = set(data_dict['IntersectCollisions'].columns)\n",
        "            break\n",
        "\n",
        "    non_i_columns = set()\n",
        "    for dict_name, data_dict in dictionaries.items():\n",
        "        if not dict_name.endswith(\"_i\") and 'RoadwayCollisions' in data_dict:\n",
        "            non_i_columns = set(data_dict['RoadwayCollisions'].columns)\n",
        "            break\n",
        "\n",
        "    same_columns = i_columns == non_i_columns\n",
        "    print(f\"Do IntersectCollisions (_i) and RoadwayCollisions (non-_i) have the same columns? {same_columns}\")\n",
        "\n",
        "    if not same_columns:\n",
        "        print(\"Columns in IntersectCollisions (_i) but not in RoadwayCollisions (non-_i):\")\n",
        "        print(i_columns - non_i_columns)\n",
        "        print(\"Columns in RoadwayCollisions (non-_i) but not in IntersectCollisions (_i):\")\n",
        "        print(non_i_columns - i_columns)\n",
        "\n",
        "check_column_consistency(all_dictionaries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-cMcyO-FOmp"
      },
      "outputs": [],
      "source": [
        "roadway_collisions_list = []\n",
        "intersect_collisions_list = []\n",
        "\n",
        "for dict_name, data_dict in all_dictionaries.items():\n",
        "    if not dict_name.endswith(\"_i\"):\n",
        "        roadway_collisions_list.append(data_dict['RoadwayCollisions'])\n",
        "\n",
        "for dict_name, data_dict in all_dictionaries.items():\n",
        "    if dict_name.endswith(\"_i\"):\n",
        "        intersect_collisions_list.append(data_dict['IntersectCollisions'])\n",
        "\n",
        "collision_counts = pd.concat(roadway_collisions_list + intersect_collisions_list, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXwqcsLtrUaV"
      },
      "outputs": [],
      "source": [
        "collision_counts['CollisionID'] = collision_counts['CollisionID'].astype(str).str.replace(r'\\.0$', '', regex=True)\n",
        "collision_counts['CollisionKey'] = collision_counts['CollisionKey'].astype(str).str.replace(r'\\.0$', '', regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etiY0uNCHO67"
      },
      "outputs": [],
      "source": [
        "# collision_counts.to_csv(\"collision_counts.csv\", index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhSwREKeHZlL"
      },
      "source": [
        "collision_counts is the df that conbine all sheets that include collision counts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYyICRcNHWH4"
      },
      "outputs": [],
      "source": [
        "## Now let's merge the second sheet\n",
        "## first drop column RoadwayReferenceMarker so all have the same structure\n",
        "def drop_column_roadway_reference_marker(data_dict):\n",
        "    data_dict['RoadwayVehiclesContrFactors'].drop(\n",
        "        columns=['RoadwayReferenceMarker'],\n",
        "        inplace=True,\n",
        "        errors='ignore'\n",
        "    )\n",
        "\n",
        "for dict_name, data_dict in all_dictionaries.items():\n",
        "    if not dict_name.endswith(\"_i\"):\n",
        "        drop_column_roadway_reference_marker(data_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbryL8HHHdU0"
      },
      "outputs": [],
      "source": [
        "roadway_vehicles_list = []\n",
        "intersect_vehicles_list = []\n",
        "\n",
        "for dict_name, data_dict in all_dictionaries.items():\n",
        "    if not dict_name.endswith(\"_i\"):\n",
        "        roadway_vehicles_list.append(data_dict['RoadwayVehiclesContrFactors'])\n",
        "\n",
        "for dict_name, data_dict in all_dictionaries.items():\n",
        "    if dict_name.endswith(\"_i\"):\n",
        "        intersect_vehicles_list.append(data_dict['IntersectVehiclesContrFactors'])\n",
        "\n",
        "factors = pd.concat(roadway_vehicles_list + intersect_vehicles_list, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5wcqcrXrZrU"
      },
      "outputs": [],
      "source": [
        "factors['CollisionID'] = factors['CollisionID'].astype(str).str.replace(r'\\.0$', '', regex=True)\n",
        "factors['CollisionKey'] = factors['CollisionKey'].astype(str).str.replace(r'\\.0$', '', regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QjOe4L0iHflU"
      },
      "outputs": [],
      "source": [
        "# factors.to_csv(\"factors.csv\", index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H79U6Jg1HidL",
        "outputId": "88acd7d8-7aea-40b0-9d6f-ec5744993235"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['CollisionID', 'CollisionKey_x', 'Borough_x', 'RoadType_x', 'VehicleSequenceNumber', 'VehicleTypeCode', 'VehicleTypeDescription', 'ContributingFactorCode', 'ContributingFactorDescription', 'OccurrencePrecinctCode', 'CollisionKey_y', 'Borough_y', 'RoadType_y', 'Collision_ at_Location', 'Address', 'CollisionVehicleCount', 'CollisionInjuredCount', 'CollisionKilledCount', 'Vehicles_or_MotoristsInvolved', 'PersonsInjured', 'PersonsKilled', 'MotoristsInjured', 'MotoristsKilled', 'PassengInjured', 'PassengKilled', 'CyclistsInjured', 'CyclistsKilled', 'PedestrInjured', 'PedestrKilled', 'Injury_or_Fatal', 'Bicycle']\n"
          ]
        }
      ],
      "source": [
        "## now, everything together\n",
        "## CollisionID as the primary key\n",
        "df = factors.merge(collision_counts, on='CollisionID', how='left')\n",
        "df = df.loc[:, ~df.columns.duplicated()]\n",
        "print(df.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZggWelNWuHc7"
      },
      "outputs": [],
      "source": [
        "df = df.drop(columns=['CollisionKey_y', 'Borough_y', 'RoadType_y'])\n",
        "df = df.rename(columns=lambda col: col.replace('_x', '') if col.endswith('_x') else col)\n",
        "df['CollisionKey'] = df['CollisionKey'].astype(str).str.replace(r'\\.0$', '', regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNftuhQcHsfm"
      },
      "outputs": [],
      "source": [
        "# df.to_csv(\"df.csv\", index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zt925bHoH3zN"
      },
      "source": [
        "Huizhen Jin's note: Be careful when using df: mass multicolinearity. As we know, one incedent can involve multiple parties but in data have the same injuries or death count, so it can be not accurate. For example, for one incident, a bus hit a bike; the bus is accounted for most of the counts, but in df it will show the same for bikc. So, really be careful. I think using factors and collision_counts are mostly enough, but just in case, here is a total df. Tell me if anything needed!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
